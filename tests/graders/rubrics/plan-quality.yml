# Plan Quality Rubric
# Used by LLM-based grader to evaluate plan agent output
#
# Model: Use Sonnet for judging (cost-effective balance)
# Calibration: Compare against human expert grades monthly

name: plan-quality
description: Evaluate the quality of implementation plans generated by the plan agent
model: claude-sonnet
version: "1.0.0"

# Grading instructions for the LLM judge
system_prompt: |
  You are evaluating an implementation plan generated by an AI agent.
  Score each criterion on a 1-5 scale based on the rubric provided.
  Be objective and consistent. Focus on whether the plan would enable
  successful implementation, not on style preferences.

criteria:
  - name: specificity
    weight: 0.30
    description: "Steps reference specific files and line numbers"
    scale:
      5: "Every step has exact file paths and line numbers where changes will be made"
      4: "Most steps have file paths, some have line numbers"
      3: "Steps have file paths but rarely line numbers"
      2: "Steps reference general areas but not specific files"
      1: "Steps are vague like 'update the auth code' without file references"

  - name: ordering
    weight: 0.20
    description: "Steps are in correct dependency order"
    scale:
      5: "Perfect dependency ordering - each step can be executed after previous completes"
      4: "Minor ordering issues that wouldn't cause failures"
      3: "Some steps are out of order but recoverable"
      2: "Multiple ordering issues that would cause rework"
      1: "Steps would fail if executed in the given order"

  - name: scope
    weight: 0.25
    description: "Plan stays within spec requirements (no scope creep)"
    scale:
      5: "Plan addresses exactly what's in the spec, nothing more"
      4: "Plan addresses spec with minor justified additions"
      3: "Plan includes some unnecessary work beyond spec"
      2: "Significant work beyond spec requirements"
      1: "Plan addresses many things not in the spec"

  - name: completeness
    weight: 0.25
    description: "All spec requirements are addressed"
    scale:
      5: "Every requirement in the spec has corresponding steps"
      4: "All major requirements covered, minor gaps"
      3: "Most requirements covered but some gaps"
      2: "Several requirements not addressed"
      1: "Many spec requirements missing from plan"

# Passing threshold (weighted average)
passing_threshold: 3.5

# Output format expected from judge
output_format: |
  ```json
  {
    "scores": {
      "specificity": <1-5>,
      "ordering": <1-5>,
      "scope": <1-5>,
      "completeness": <1-5>
    },
    "weighted_average": <float>,
    "pass": <true|false>,
    "reasoning": "<brief explanation>"
  }
  ```

# Example for calibration
examples:
  - input: |
      Plan for "Add Logout Button":
      1. Update src/components/Header.js to add logout button
      2. Call logout function on click
      3. Test it works
    expected_score: 2.0
    reasoning: "Vague steps without line numbers, missing redirect and localStorage cleanup from spec"

  - input: |
      Plan for "Add Logout Button":
      1. In src/components/Header.js:23, add LogoutButton component import
      2. In src/components/Header.js:45-50, add button in header-right div
      3. In src/components/Header.js, add onClick handler calling useAuth().logout()
      4. In src/context/AuthContext.js:42, verify logout() clears localStorage
      5. Add redirect to /login after logout in Header component
      6. Write unit test in src/__tests__/Header.test.js for logout button visibility
    expected_score: 4.5
    reasoning: "Specific file:line references, correct ordering, addresses all spec requirements"
